\chapter{NMA of Pancreatic Cancer Trials}\label{nmachap}

\section{Network of Evidence}
Figure~\ref{fig:osnet} presents the network of evidence for this NMA. There were two studies comparing GEM with GEM-AXI, but only one study for each other comparison. As indicated by the size of each node, GEM-SOR was the treatment with the lowest sample size, and GEM-NAB was the comparator with the highest. The GEM $\to$ GEM-NAB edge is a different colour due to being an IPD trial. 

\begin{figure}[h]
    \centering
    \includegraphics[width = \textwidth]{../figures/OS_Network.png}
    \caption{Network of evidence}
    \label{fig:osnet}
\end{figure}

\section{Model Fitting and Selection}
Both FE and RE models were fit using gamma, generlaised gamma, Gompertz, log-logistic, log-normal, and Weibull likelihoods. Vague priors were used for each model. Namely, the intercept prior was $N(0, 100)$, the treatment prior was $N(0, 10)$, the auxiliary prior was $hN(0, 5)$, and auxiliary regression prior was $N(0, 10)$. Here, $hN$ denotes a \textit{half-normal distribution}, as defined in Defintion~\ref{def:hndef}. For each model, sampling was done using 1000 iterations on four chains. The first 500 iterations were warmup iterations. \\

Table~\ref{tab:selectionstatbc} presents the selection statistics for each model. The fixed effect model was also deemed to be clinically appropriate due to homogeneity in the patient population. The FE gamma, FE and RE generalised gamma models failed to converge, meaning no DIC or LOOIC estimates could be obtained. The RE gamma and RE Gompertz models gave LOOIC and DIC scores so high that they were classified as Inf, indicating poor fit. The log-logistic, log-normal, and Weibull models gave similar LOOIC and DIC scores. In each case, the FE model had slightly lower LOOIC than the RE model for each likelihood. The FE log-normal model gave the lowest LOOIC and DIC score, indicating it was the best fitting model. The trace plot for this model is available in Appendix~\ref{NMAAppendix}, Figure~\ref{fig:tracebc}, and indicated good convergence due to consistent peaks and troughs across each treatment arm. \\

\begin{table}[h]
    \centering
    \begin{tabular}{llll}
    \hline
    Likelihood   & Effect & DIC         & LOOIC      \\ \hline
    Gamma        & Fixed  & NA          & NA         \\
    Gamma        & Random & Inf         & Inf        \\
    Gen Gamma    & Fixed  & NA          & NA         \\
    Gen Gamma    & Random & NA          & NA         \\
    Gompertz     & Fixed  & 15388.1764  & 15381.1184 \\
    Gompertz     & Random & Inf         & Inf        \\
    Log-logistic & Fixed  & 15176.9789  & 15176.0719 \\
    Log-logistic & Random & 15175.2325  & 15176.2254 \\
    Log-normal   & Fixed  & 15172.3036 $\leftarrow$ & 15173.0542 $\leftarrow$ \\
    Log-normal   & Random & 15172.7801  & 15173.3975 \\
    Weibull      & Fixed  & 15200.20470 & 15200.1331 \\
    Weibull      & Random & 15199.29711 & 15200.6538 \\ \hline
    \end{tabular}
    \caption{Model selection statistics for each model}
    \label{tab:selectionstatbc}
\end{table}

\section{Results}
Figure~\ref{fig:pred_surv} and Figure~\ref{fig:pred_hazard} present the predicted survival and hazard of each treatment in study population, respectively. GEM-NAB and GEM-CAP had the highest OS and lowest hazard in each study population. The hazard curves for each study in each population followed a similar pattern, with peaks in the hazard just before ten months, before declining. GEM-SOR had the highest peak-hazard in each population, but crossed the GEM hazard curve in each population shortly after the peak, finishing with a lower hazard than GEM by the end of the observation period in each population. Further, in terms of hazard, the GEM-AXI and GEM-PEM curves were almost identical in each population. \\

Figure~\ref{fig:pred_rmstbc} presents the estimated RMST of each treatment in each population. The GEM-SOR arm had large credible intervals in each population due to the lower number of patients for which GEM-SOR data was available. Further, GEM-SOR and GEM-IRI had the lowest and second-lowest RMST estimates in each population, respectively. The RMST estimates for GEM, GEM-AXI, and GEM-PEM were similar in each population, as were GEM-CAP, and GEM-NAB. GEM-NAB and GEM-CAP had the highest and second-highest RMST estimates respectively in every study population. \\

Figure~\ref{fig:pred_medianbc} presents the estimated median OS of each treatment in each population. The median OS estimates followest the same pattern as the RMST estimates. Namely, GEM-SOR and GEM-IRI gave the lowest and second-lowest estimates for median OS in each study population, GEM, GEM-AXI, and GEM-PEM gave similar estimates, and GEM-NAB and GEM-CAP gave the highest and second-highest estimates of median OS, respectively. The median OS estimates of GEM-NAB and GEM-CAP were further apart than the RMST estimates for the same two treatments. 

\begin{figure}[h]
    \centering
    \includegraphics[width = \textwidth]{../Results/NMA/Survival_Plot.png}
    \caption{OS of each treatment in each population}
    \label{fig:pred_survbc}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = \textwidth]{../Results/NMA/Hazard_Plot.png}
    \caption{Hazards of each treatment in each population}
    \label{fig:pred_hazardbc}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = \textwidth]{../Results/NMA/RMST_Plot.png}
    \caption{RMST of each treatment in each population}
    \label{fig:pred_rmstbc}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width = \textwidth]{../Results/NMA/Median_Plot.png}
    \caption{Median OS of each treatment in each population}
    \label{fig:pred_medianbc}
\end{figure}

\section{Considerations for the ISPOR Good Practice Task Force}
The Progessional Society for Health Economics and Outcomes Research (ISPOR) developed a 26-item questionnaire for assessing the credibility of an NMA~\cite{jansengp}. This NMA was performed inline with these practices. While each question is not answered individually here, the themes of the guidance, and how this NMA aligns with it, are discussed. \\

The first set of questions in the guidance concerns the evidence base. This NMA was performed on a fully-connected network of evidence (Figure~\ref{fig:osnet}), and included no poor-quality studies. Indeed, the study populations and trial characteristics were similar, meaning there was no systematic differences in treatment effect modifiers across the comparisons. The only aspect of this NMA that could be considered not to follow these guidelines was that not all available RCTs were included. The Greshem study, for example included 23 studies obtained by seaching several databases. This NMA was not conducted based on results of a systematic literature review or database search. Studies were selected for this NMA based on a brief literature search for trials comparing GEM with another therapy. Since all the KM curves from published papers had to be digitised, which takes a considerable amount of time, there was always to be a limit on how many studies could be included. \\

The second set of questions concerns the analysis. No na\"ive comparisons were made, which preserve within-study randomisation. As there were no cases of both direct and indirect evidence for any treatments, questions eight and nine were not deemed relevant. Question ten concerns imbalance of the distribution of effect modifiers, and how this was accounted for. Since the ML-NMR is a meta-regression model, this was directly accounted for. In terms of FE and RE models, both were fit, and the best fitting model selected in terms of robust selection statistics. Since the studies included in this NMA were not diverse in terms of methodology, FE models were deemed to be clinically appropriate. The guidance generally reccomends RE models, but it was deemed clinically appropriate to consider FE models in this case. Were more trials to be included, more consideration would need to be given to the similarity assessment to determine the suitability of FE models. \\

The third set of questions relates to the reporting quality. while all the studies used, and indeed the associated KM curves were presented, the actual TTE data was not presented. This is due to the form of the data, although it is available within \verb|PCNMA| R package. Individual study results were provided in Figures~\ref{fig:pred_survbc}-~\ref{fig:pred_medianbc}. Considerations did not have to be made for direct and indirect comparisons since there were no closed loops. Rankings were reported to address the main project aim, and pairwise comparisons were reported. In particular, the pairwise comparison between GEM-CAP and GEM-NAB was important to clarify the uncertainty mentioned by NICE in NG85. No consideration was given to the effect of important patient characteristics due to the homogeneity in the trial populations and further because of a lack of IPD available for this study. It is not sound for those involved in the study to assess the fairness of the conclusions and interpretation, but every attempt was made to perform this NMA with integrity and interpret the results in line with the evidence. \\

