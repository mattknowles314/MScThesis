\chapter{Survival Analysis Bakground}\label{survchap}

\section{Survival Functions}

Given a homogeneous population of individuals, the time of death for each individual is drawn from a continuous random variable $T > 0$ with probability density function $f(t)$ and distribution function $F(t) = \int_{0}^{t}f(\tau)d\tau$. Survival analysis is concerned with estimating the distribution $T$ from Time-To-Event (TTE) data. There are two functions central to survival analysis, the \textit{survival function} and \textit{hazard function}.

\begin{definition}{Survival Function}{h}
    The \textbf{Survival Function} $S(t)$, gives the probability of an individual surviving longer than time $t$. 
    \begin{equation}
        S(t) = P(T \geq  t) = 1 - F(t) = \int_{t}^{\infty}f(\tau)d\tau  
    \end{equation}
\end{definition}

\begin{definition}{Hazard Function0}{h}
    The \textbf{Hazard Function} gives the risk of death at time $t$, given that the individual has survived up to time $t$. 
    
    \begin{equation}
        h(t) = -\frac{d}{dt}\log S(t)  
    \end{equation}
\end{definition}

\section{The Kaplan-Meier Estimator and Reconcstructing Patient-Level Data}
\subsection{The Kaplam-Meier Estimator}
The KM estimator is a non-parametric method for estimating the survival function from event and censoring times. TTE data contains, at a bare minimum, a subject identifier, an event time, and a censoring indicator. The Censoring indicator is given in Equation~\ref{censInd}. The time column of data gives the time that either the event (i.e, death due to the disease being investigated, in overall survival), or censoring (i.e a chemotherapy patient dies due to an adverse event unrelated to their cancer) occurs.

\begin{equation}
    c_{i} = \begin{cases}
        1 \ \text{If inividual i has an event} \\
        0 \ \text{If individual i is censored}
    \end{cases}
    \label{censInd}  
\end{equation}

Let $d_i$ and $n_i$ be the number of events and total individuals at risk at the $i^{th}$ timepoint, $t_i$. Define the discrete hazard rate $h_i$ as the probability that individual experiences an event at time $t_i$. The survival rate is then defined as in Equation~\ref{survrate}, and the likelihood function for the hazard function up to time $t_i$ is given by Equation~\ref{hazllhood}.

\begin{equation}
    S(t) = \prod_{i:t_i \leq t} (1 - h_i)
    \label{survrate}
\end{equation}

\begin{equation}
    \mathcal{L}(h_{j\leq i}|d_{j:j\leq i}, n_{j:j\leq i}) = \prod_{j=1}^i h_j^{d_j}(1-h_j)^{n_j-d_j}\binom{n_j}{d_j}
    \label{hazllhood}
\end{equation}

The KM estimator can be derived by MLE of the discrete hazard function. By obtaining an maximum likelihood estimate of $h_i$, $\hat{h_i}$, and substituting it into Equation~\ref{survrate}, the resulting estimate of the survival function, $\hat{S(t)}$, will be the KM estimator. Taking the logarithm of both sides of Equation~\ref{hazllhood} gives Equation~\ref{loghazlik}.

\begin{equation}
    log(\mathcal{L}) = \sum_{j=1}^i \left(d_j\log(h_j)+(n_j-d_j)\log(1-h_j) + \log \binom{n_j}{d_j}\right)
    \label{loghazlik}
\end{equation}

By taking the derivative of Equation~\ref{loghazlik} with respect to $h_i$, and setting the resulting fraction equal to zero, $\hat{h_i}$ is obtained as in Equation~\ref{kmHaz}.

\begin{align}
    \frac{\partial \log(\mathcal{L})}{\partial h_i} &= \frac{\partial}{\partial h_i}\left(\sum_{j=1}^i \left(d_j\log(h_j)+(n_j-d_j)\log(1-h_j) + \log \binom{n_j}{d_j}\right)\right) \\
    &= \frac{d_i}{\hat{h_i}} - \frac{n_i - d_i}{1 - \hat{h_i}}
\end{align}

\begin{equation}
    \Rightarrow \frac{\partial \log (\partial )}{\partial h_i} = 0 \Rightarrow \hat{h_i} = \frac{d_i}{n_i}
    \label{kmHaz}
\end{equation}

\begin{definition}[label={kmEst}]{Kaplain-Meier Estimator}
    TThe \textbf{Kaplan-Meier Estimator}, $\hat{S(t)}$, estimates the survival probability that an individual survives longer than time $t$, and is given by Equation~\ref{kmeq}. 
\begin{equation}
    \hat{S(t)} = \prod_{i:t_i \leq t}\left(1 - \frac{d_i}{n_i}\right)
    \label{kmeq}
\end{equation}
\end{definition}

\section{Reconstructing Survival Data from Published Curves}
The ML-NMR method requires aggregate survival data to be in the form of the TTE data previously described. Often, the actual patient level event and censoring times/indicators are not published, and therefore must be reconstructed from the published KM curves, which are usually readily available. Indeed, one of the study selection criteria outlined in Section~\ref{sec:aims} was that studies must publish KM curves with numbers at risk. This was motivated by the method for reconstructing patient-level data from KM curves, the Guyot algorithm~\cite{guyotipd} requiring numbers at risk.

\section{Regression Models for Survival}
The survival time of patients may be dependent on several explanatory variables such as age, sex, the presence of a genetic mutation, etc. We wish to incorperate these variables into our survival functions. There are two forms of models for survival data: Accelerated Failure Time (AFT) models, and Proportional-Hazards (PH models).

\subsection{Accelerated Failure Time Models}

Let $x$ be a vector of explanatory variables for each individual in a trial. The survival function can be extended to include this,

\[
    S(t, x) = S_0(t\Psi(x)).
\]

Here, $S_0(t) = S(t, x = 0)$, i.e the survival function at baseline. We define the density and hazard functions accordingly,

\begin{align*}
    f(t, x) &= f_0(t\Psi(x))\Psi(x) \\
    h(t, x) &= h_0(t\Psi(x))\Psi(x).
\end{align*}

This is equivalent to defining a random variable $T$ such that

\[
    T = T_0/\Psi(x).  
\]

Here, $T_0$ has survival function $S_0$. It is required that $\Psi(x) \geq 0$ and $\Psi(0) = 1$, leading to the natural choice 

\[
    \Psi(x) = \exp(-\beta'x).  
\]

We can then write 

\begin{align*}
    T &= T_0/\Psi(x) \\
    \implies E(T) &= E(T_0)/E(e^{-\beta'x}) \\
    &= E(T_0)/e^{-\beta'x} \\
    &= E(T_0)e^{\beta'x}
\end{align*}

In practice, we assume a distribution for $T$, and estimate parameters using MLE. 

\subsection{Proportional Hazards Models}

Let $h_0$ represent the hazard function for an individual at baseline. In addition, let $x$ be a vector of explanatory variables. The proportional hazards model, also known as the Cox model~\cite{cox1972} is then given by 

\begin{equation}
    h(t, x) = \exp(\beta'x) \ h_0(t)
    \label{coxmodel}
\end{equation}

The Cox model is semi-parametric model (Definition~\ref{semPam}) then $\beta$ is of finite dimension and $h_0(t)$ is infinite-dimensional and does not need to be specified. 

\begin{definition}[label=semPam]{Semi Parametric Model}{h}
    A statistical model is a parameterised family of distributions $\{P_{\theta} : \theta \in \Theta\}$. 
    For a parametric model, $\Theta \subseteq \mathbb{R}^k$ for $k \in \mathbb{N}$. Similarly, for a non-parametric model, $\Theta \subseteq V$, where $V$ is some (possibly infinite) dimensional space $V$. A \textbf{Semi-parametric} model is a statistical model with both parametric and non-parametrc components. For a semi-parametric model we have $\Theta \subseteq \mathbb{R}^k \times V$.
\end{definition}


\section{Key Survival Metrics}

\subsection{The Hazard Ratio}
The Hazard Ratio (HR), often denoted using $\varphi$, follows from Equation~\ref{coxmodel}. Consider two treatments, $i = 1, 2$, then $h_1(t, x) = \exp(\beta'x) \ h_0(t)$ and $h_2(t, x) = \exp(\beta'x) \ h_0(t)$. The HR is obtained as in Equation~\ref{HReq}.

\begin{equation}
    \varphi = \frac{h_1}{h_2} = \exp(\beta' x)
    \label{HReq}
\end{equation}

In practice, the HR is a useful endpoint in performing NMAs on survival outcomes. However, in order to conduct a HR-based NMA, the proportional hazards assumption (PHA), must be satisfied. The PHA is the assumtpion that the HR remains constant throughout the observation period of a trial. It can be tested by, for example, visual-inspection of a log-cumulative hazards plot. The log-cumulative hazard plot comes from the cumulative hazard function (Definition~\ref{cumHazFun}), which gives the cumulated risk of experiencing an event. Given the cumulative nature of the cumulative hazard function, and the nature of $S(t)$ being monotonically decreasing, the cumulative hazard function is monotonically increasing.

\begin{definition}[label=cumHazFun]{Cumulative Hazard Function}
    BThe \textbf{Cumulative Hazard Function}, $H(t)$ is given by 
    \begin{equation}
        H(t) = \int_{0}^{x}h(t)dt = -\log(S(t))  
    \end{equation}
\end{definition}

By extention, the log-cumulative hazard function is given by $\log(-\log(S(t)))$. When plotting this for both arms of a clinical trial, if the curves remain roughly parallel, the PHA is likely satisfied. If the curves cross and/or diverge, it indicates PHA has not been satisfied. Whether the PHA is satisfied has implications later on in the analysis. For example, if the PHA is not satisfied, then an individual model must be used for each treatment arm. If the PHA is satisfied, a model which does not include a treatment parameter may be appropriate. This fits a single model to one treatment arm, and then uses a linear coefficient used for obtaining estimates of survival for the non-reference treatment. It is clear to see why this would be be inappropriate if the PHA is not violated, since the difference betweem survival curves will not be linear. 

\subsection{Median Survival}
Median survival is simply the earliest timepoint after which 50\% of patients have died. 

\subsection{Restriced Mean Survival Time}
The RMST is alternative measure to the (log) HR in NMAs. RMST is the mean survival time up to a pre-specified time. This measure can be thought of visually as the area under the survival curve. Definition~\ref{def:rmst} presents the formal definition.


\begin{definition}[label=def:rmst]{RMST}
    AFor a survival function $S(t)$, the \textbf{RMST} for some pre-specified time $x > 0$,
    \begin{equation}
        RMST = \int_{0}^{x} S(t)dt
    \end{equation}
\end{definition}

\section{Parametric Models for Survival Analysis}
This section discusses the parametric models commonly used in Survival Analysis. In particular, the seven parametric models recommended by the NICE in Technical Support Document (TSD) 14~\cite{tsd14}. All parametric model fitting for this project was performed in \verb|R| using the \verb|flexsurv| package~\cite{flexsurv}. The first section outlines how the \verb|flexsurv| package works.

\subsection{Model Setup}
The general model of a \verb|flexsurv| survival model takes the form 

\begin{equation}
    \label{fsurvmodel}
    f(t|\mu(\bf{z}), \bf{\alpha}(\bf{z})).
\end{equation}

Equation~\ref{fsurvmodel} gives the probability density for death at time $t \geq 0$. The \textit{mean} or \textit{location} of the distribution is given by $\mu = \alpha_0$. The remaining parameters, $\bf{\alpha^1} = (\alpha_1, \ldots, \alpha_R)$ are called \textit{ancillary} parameters. \\

Chapter~\ref{survchap} discussed AFT and PH models. Under the \verb|flexsurv| framework, if the hazard function, $h(t) = \frac{f(t)}{S(t)}$, can be factorised as in Equation~\ref{flex1}, then the model is a PH model. Alternatively, if the survival function is written as in Equation~\ref{flex2}, then the model is an AFT model.

\begin{equation}
    h(t|\bf{\alpha}, \mu(z)) = \mu(z)h_0(t|\alpha). 
    \label{flex1}
\end{equation}

\begin{equation}
    S(t|\mu(\bf{z}), \bf{\alpha}) = S_0(\mu(\bf{z})t/\bf{\alpha}).  
    \label{flex2}
\end{equation}

All parameters may depend on $z$, a vector of covariates. This is done through the link-transformed linear models in Equation~\ref{flexsurvMLE1} and Equation~\ref{flexsurvMLE2}.

\begin{align}
    g_0(\mu(z)) &= \gamma_0 + \beta_0^Tz \label{flexsurvMLE1}\\
    g_r(\alpha_r(z)) &= \gamma_r + \beta_{\gamma}^Tz \label{flexsurvMLE2}
\end{align}

In Equation~\ref{flexsurvMLE1} and Equation~\ref{flexsurvMLE2}, $g$ is usally chosen to be $log()$ if the parameter is positive, or the identity function if the parameter is unrestricted.

\subsection{Fitting Models}
Let $t_i$, $i \in \{1, \ldots, n\}$, be a sample of times from $n$ individuals. Define $c_i$ as in Equation~\ref{censInd}. Introduce $s_i$, which are delayed-entry times. This means for an individual $i$ who is delayed-entry, the survival time is only observed conditionally on individual $i$ having survived up to time $s_i$. Therefore, $s_i = 0$ when there is no delayed-entry. 

\subsubsection{Right Censoring}
In the case of right-censoring and nothing else, the likelihood for the parameters $\bf{\theta} = \{\bf{\gamma}, \bf{\beta}\}$ required in Equation~\ref{flexsurvMLE1}-\ref{flexsurvMLE2} is given by 

\begin{equation}
    l(\bf{\theta}|t,c,s) = \frac{\prod_{i:c_i=1} f_i(t_i) \prod_{i:c_i=0} S_i(t_i)}{\prod_{i} S_i(s_i)}
    \label{flexsurvRightCens}
\end{equation}

\subsubsection{Interval Censoring}
In the case of interval-censoring, where the survival time is censored on $(t_i^{\text{min}}, t_i^{\text{max}})$, the likelihood for $\theta = \{\gamma, \beta\}$ is 

\begin{equation}
    \label{flexSurvIntCens}
    l(\theta|t^\text{min}, t^\text{max}, c,s) = \frac{\prod_{i:c_i=1} f_i(t_i) \prod_{i:c_i=0} \left(S_i(t_i^{\text{min}}) - S_i(t_i^{\text{max}}) \right)}{\prod_{i} S_i(s_i)}
\end{equation}

MLE is performed in \verb|R| using the analytic derivatives of Equation~\ref{flexsurvRightCens} and/or Equation~\ref{flexSurvIntCens} to obtain the required survival models. 

\subsection{Model selection Considerations}
Once a set of models has been fit to the data from a trial, the best model must be selected. NICE DSU TSD 14~\cite{tsd14} gives guidance on the model selection process. \\

The first thing to consider is the visual fit. By overlaying the fitted model(s) over the observed data, it is easy to see how well the two align. Indeed, this is not a particularly robust method of selection, but does provide a quick way to discount certain models. \\

The second, more robust, method is to examine the Akaike\'s Information Criterion (AIC) score~\cite{akaike} (Definition~\ref{def:AIC}). The values of the AIC scores for each model do not intrinsicly reflect the best fitting model, but instead the model with the lowest value is considered to be the best fitting. TSD 14 discusses the use of the Bayesian Information Criterion (BIC) score~\cite{schwarz} (Definition~\ref{def:BIC}) in addition to the AIC score due to the ability to account for the number of model parameters. The model with the lowest AIC (or BIC) score is deemed to be the best fitting model. Futher to this, models that score within a score of two of the best fitting model are also appropriate models. The AIC and BIC scores do not give any information about the quality of the models, so further assessment of the best\-fitting models is therefore required.

\begin{definition}[label=def:AIC]{AIC Score}
    CConsider a statistical model with $k$ estimated parameters and $\hat{L}$ be the maximised value of the likelihood function of the model. TThe Akaikie's Information Criterion (AIC) score for this model is given as in Equation~\ref{eq:AIC}.

    \begin{equation}
        AIC = 2(k - \log(\hat{L}))
        \label{eq:AIC}
    \end{equation}
\end{definition}

\begin{definition}[label=def:BIC]{BIC Score}
    CConsider a statistical model with $k$ estimated parameters and $\hat{L}$ be the maximised value of the likelihood function of the model. Further, et $n$ be the number of data points in the observed data to which the model was fitted. The Akaikie's Information Criterion (AIC) score for this model is given as in Equation~\ref{eq:BIC}.

    \begin{equation}
        BIC =  k\log(n) - 2\log(\hat{L})
        \label{eq:BIC}
    \end{equation}
\end{definition}

In the context of parametric survival models, the BIC score may be surplus to requirements two reasons.

\begin{enumerate}
    \item Five of the seven parametric models recommended by NICE have the same number of parameters, $k = 2$, so no extra information is gained by using the BIC score. \\
    \item The AIC score is preferable for models being used in a predictive context, which is of course the case for survival analysis.
\end{enumerate}

Consider item (1). This can be further reduced based on whether or not the PHA holds. If the PHA has been deemed to be violated by sufficient testing, then the exponential model is not an appropriate model, leaving five models with $k = 2$ and one model, the generalised gamma model with $k = 3$. Let $k_A = 3$ and $k_B = 2$ be such that model $A$ is the generalised gamma model, and model $B$ is one of the other five models. The AIC score difference is given in Equation~\ref{eq:aicdiff1}\-\ref{eq:aicdiff3}, and the BIC score difference is given in Equation~\ref{eq:bicdiff1}\-\ref{eq:bicdiff3}, the difference between the difference of the differences reduces to  Equation~\ref{eq:dicDiff}, which shows that each comparison of the generalised gamma model to another model will be offset by the same amount. Further to this, since five of the models all have $k = 2$, Equations~\ref{eq:aicdiff1}-\ref{eq:aicdiff3} and Equations~\ref{eq:bicdiff1}-\ref{eq:bicdiff3} both reduce to $\log\left(\frac{\hat{L_B}}{\hat{L_A}}\right)$. Since the difference between BIC scores for each $k = 2$ model and the generalised gamma model is offset by a linear amount, the same conclusions would be drawn whether using AIC or BIC scores. \\

If the PHA holds, then exponential model is of course acceptable, then the reasoning the PHA-violated case holds for comparing $k = 2$ models to the exponential model, and the generalised gamma model to the $k = 2$ models, however, the difference between the generalised gamma model and exponential model will replace $\log(n)$ with $2\log(n)$ in Equation~\ref{eq:bicdiff3} and replace $2$ with $4$ in Equation~\ref{eq:aicdiff3}, but the same argument as before follows, since the likelihood is still the main driver of difference. As the number of model parameters increases, this argument breaks down, since the $2(k_A - k_A)$ term in the AIC difference will grown much quicker then $(k_B-k_A)\log(n)$ term, leading to unnecssarily large AIC values. However, when the maximum difference between the $k$ terms is $2$, as in the case of parametric survival models, little to no extra information is gained by using the BIC score over the AIC score. 

\begin{align}
    \delta_{AIC} &= AIC_A - AIC_B \label{eq:aicdiff1}\\
           &= 6 - 2\log(\hat{L_A}) - (4 - 2\log(\hat{L_B})) \\
           &= 2 + 2\log\left(\frac{\hat{L_B}}{\hat{L_A}}\right) \label{eq:aicdiff3}
\end{align}

\begin{align}
    \delta_{BIC} &= BIC_A - BIC_B \label{eq:bicdiff1}\\
           &= 3\log(n) - 2\log(\hat{L_A}) - (2\log(n) - 2\log(\hat{L_B})) \\
           &= \log(n) + 2\log(\hat{L_B}) - 2\log(\hat{L_A}) \\
           &= \log(n) + 2\log\left(\frac{\hat{L_B}}{\hat{L_A}}\right) \label{eq:bicdiff3}
\end{align}

\begin{align}
    \delta_{IC} &= \delta_{BIC} - \delta_{AIC} \\
                &= \log(n) - 2 \label{eq:dicDiff}
\end{align}

Item (2), which is the more important, and slightly less specific to this particular scenario, reason for prioritising the AIC score. Survival models are inherently predictive. The purpose is to assess how the survival of a population will evolve over an unseen period without having to keep an RCT running for an indefinite amount of time until all patients have left the study. The AIC method is \textit{minimax\-rate optimal}~\cite{ding}, meaning the the maximum loss of information reduces at an optimal rate as the sample size increases. These definitions are information theoretic, and beyond the scope of this dissertation, but it does mean that the AIC model is more appropriate for predictive models. \\

For these reasons, only the AIC score was used for survival model selection in this dissertation. The BIC score would be used if the AIC scores gave inconclusive estimates. 