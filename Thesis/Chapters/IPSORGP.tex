\chapter{ISPOR Good Practice Questions}\label{isporqs}

\section{Evidence Base}
\textbf{Is the population relevant?} Yes. The populations in these trials were reflective of people most likely to have advanced/metastatic pancreatic cancer. \\ 

\textbf{Are any relevant interventions missing?} Potentially. The Gresham NMA included 19 treatments in total. This NMA included all of the best-performing treatments from the Gresham study, but could be expanded to include more studies in the future. The treatments in this NMA however were chosen as the ones most likely to be of interest to a decision maker in a clinical setting. \\ 

\textbf{Are any relevant outcomes missing?} No PFS data was included. The puprose of this NMA was for assessing the OS endpoint, but the same methods would apply with PFS data. \\

\textbf{Is the context (settings and circumstances) applicable?} Treatment for pancreatic cancer has not changed much over the last 25 years. Indeed, while the studies used in this NMA were reported between 2004 and 2015, all the treatments are still relevant in 2024. If surgical studies had been included, there may be some discussion required, as more attempts are being made to operate on pancreatic cancer nowadays. \\

\textbf{Did the researchers attempt to identify and include all
relevant RCTs?} No. no thorooguh literature was performed for this NMA. Studies were selected based on how well they were reported, due to considerations with digitising the KM curves, and whether the comparators were relevant. As mentioned previously, the best-performing treatments from the Gresham study were of primary interest for this NMA.\\

\textbf{Do the trials for the interventions of interest form one
connected network of RCTs?} Yes, see Figure~\ref{fig:osnet}.\\

\textbf{Is it apparent that poor quality studies were included, thereby
leading to bias?} No. The only potential comment here is the low sample size of the Spano or Goncalves studies. These studies were not deemed to be of poor quality despite this.\\

\textbf{Is it likely that bias was induced by selective reporting of
outcomes in the studies?} As only the OS endpoint was considered, this was not deemed to be a potential influencer of any bias in the NMA.\\

\textbf{Are there systematic differences in treatment effect modifiers
(i.e., baseline patient or study characteristics that have an
impact on the treatment effects) across the different treatment
comparisons in the network?} No. The populations in the included studies were more-or-less identical. We included the proportion of male patients as a covariate in order to use the ML-NMR method.\\

\textbf{If yes (i.e., there are such systematic differences in treatment
effect modifiers), were these imbalances in effect modifiers
across the different treatment comparisons identified before
comparing individual study results?} NA.\\

\section{Analysis}
\textbf{Were statistical methods used that preserve within-study
randomization? (No naive comparisons)} Yes. The NMA was based on relative treatment effects. \\

\textbf{If both direct and indirect comparisons are available for
pairwise contrasts (i.e., closed loops), was agreement in
treatment effects (i.e., consistency) evaluated or discussed?} No closed loops. Question not applicable. \\

\textbf{In the presence of consistency between direct and indirect
comparisons, were both direct and indirect evidence included in
the network meta-analysis?} No closed loops. Question not applicable. \\

\textbf{With inconsistency or an imbalance in the distribution of
treatment effect modifiers across the different types of
comparisons in the network of trials, did the researchers
attempt to minimize this bias with the analysis?} This was not deemed relevant due to the similarity of the trials. \\

\textbf{Was a valid rationale provided for the use of random-effects
or fixed-effect models?} Given the similarity of the included trials, FE models were not deemed to be clinically inappropriate. This is why both FE and RE models were fit for each likelihood. The best performing models were selected based on the LOOIC and DIC scores, rather than any clinical considerations. \\

\textbf{If a random-effects model was used, were assumptions
about heterogeneity explored or discussed?} Question not applicable as the RE model was not used.\\

\textbf{If there are indications of heterogeneity, were subgroup
analyses or meta-regression analysis with prespecified
covariates performed?} Yes, by nature of using an ML-NMR.\\

\section{Reporting quality and transparency}

\textbf{Is a graphical or tabular representation of the evidence
network provided with information on the number of RCTs per
direct comparison?} Yes, see Figure~\ref{fig:osnet}. The thickness of lines denotes the number of RCTs avaialble per comparison. \\

\textbf{Are the individual study results reported?} Yes.\\

\textbf{Are results of direct comparisons reported separately from
results of the indirect comparisons or network meta-analysis?} Question not applicable.\\

\textbf{Are all pairwise contrasts between interventions as obtained
with the network meta-analysis reported along with measures
of uncertainty?} Yes, see Figure~\ref{fig:pair_releff}.\\

\textbf{Is a ranking of interventions provided given the reported
treatment effects and its uncertainty by outcome?} Yes, see Figure~\ref{fig:sucra}. \\

\textbf{Is the effect of important patient characteristics on treatment
effects reported?} No, due to lack of IPD. \\

\section{Interpretation}

\textbf{Are the conclusions fair and balanced?} Yes. Every attempt was made to do this. \\

\section{Conflicts of Interest}

\textbf{Were there any potential conflicts of interest?} This project was somewhat personal to the author, but that personal experience did not influence the results. There was no inherent bias to a particular therapy. The author is employed by a health economics consultancy, but has no interest in a particular therapy from a commercial perspective either.\\

\textbf{If yes, were steps taken to address these?} Not required.